{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3]) # Creates a tensor from a list or numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(2, 3) # Creates a tensor with all elements set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(2, 3) # Creates a tensor with all elements set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint(10, size=(2, 5)) # Creates a tensor filled with random integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((3, 4)) # Creates a tensor filled with random float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.numel(torch.rand((3, 4))) # Returns the total number of elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((2, 4)) @ torch.rand((4, 6)) # Matrix product of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros((3, 4)).shape # Returns the shape of the tensor alias for tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10, (5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rot90(a) # Rotate a tensor by 90 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.rot90(2) # Rotate a n-D tensor by 180 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sum() # Returns the sum of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max() # Returns the maximum value of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.argmax() # Returns the indices of the maximum value of all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(a, 0) # Returns the indices of the maximum value and its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(a.argmax(), a.shape) # There is no torch.unravel_index but you can use np.unravel_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.view((2, -1)) # Returns a new tensor with the same data as the self tensor but of a different shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(10, (5, 5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.clone() # copy of the tensor\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.dtype # data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.random.randint(10, size=(2, 3))\n",
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(numpy_array) # turn numpy array into torch tensor\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_np_array = tensor.numpy() # turn torch tensor into numpy array\n",
    "another_np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.unsqueeze(1) # Converting a horizontal tensor to a vertical one\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 9))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available() # Returns a bool indicating if CUDA is currently available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device('cuda:0') # This is an object representing the device on which a tensor is or will be allocated (graphics card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.device('cpu') # for cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_on_cuda = x.to(device) # Transfer of the tensor to another device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_tensor = torch.rand(2000, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_tensor_on_cuda = big_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y = big_tensor + big_tensor**2 * big_tensor / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_cuda = big_tensor_on_cuda + big_tensor_on_cuda**2 * big_tensor_on_cuda / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation (autograd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1., 2., 3.], [4., 5., 6.]], requires_grad=True)\n",
    "\n",
    "gpu = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "x = x.to(device)\n",
    "\n",
    "x.retain_grad()\n",
    "# x.requires_grad_() # delete requires_grad=True from first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 20.,  40.,  60.],\n",
       "        [ 80., 100., 120.]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function = 10 * (x**2).sum()\n",
    "function.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x0000023557553BC8>  - multiplication\n",
      "<SumBackward0 object at 0x0000023557553C48>  - sum\n",
      "<PowBackward0 object at 0x0000023557553BC8>  - exponentiation\n"
     ]
    }
   ],
   "source": [
    "# history\n",
    "print(function.grad_fn, ' - multiplication')\n",
    "print(function.grad_fn.next_functions[0][0], ' - sum')\n",
    "print(function.grad_fn.next_functions[0][0].next_functions[0][0], ' - exponentiation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.data -= 0.001 * x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad.zero_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([8., 8.], requires_grad=True)\n",
    "var_history = []\n",
    "fn_history = []\n",
    "\n",
    "optimizer = torch.optim.SGD([x], lr=0.001)\n",
    "\n",
    "def function_parabola(variable):\n",
    "    return 10 * (variable ** 2).sum()\n",
    "\n",
    "def make_gradient_step(function, variable):\n",
    "    function_result = function(variable)\n",
    "    function_result.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "for i in range(500):\n",
    "    var_history.append(x.data.numpy().copy())\n",
    "    fn_history.append(function_parabola(x).data.cpu().numpy().copy())\n",
    "    make_gradient_step(function_parabola, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_contours(objective,\n",
    "                  x_lims=[-10.0, 10.0], \n",
    "                  y_lims=[-10.0, 10.0],\n",
    "                  x_ticks=100,\n",
    "                  y_ticks=100):\n",
    "    x_step = (x_lims[1] - x_lims[0]) / x_ticks\n",
    "    y_step = (y_lims[1] - y_lims[0]) / y_ticks\n",
    "    X, Y = np.mgrid[x_lims[0]:x_lims[1]:x_step, y_lims[0]:y_lims[1]:y_step]\n",
    "    res = []\n",
    "    for x_index in range(X.shape[0]):\n",
    "        res.append([])\n",
    "        for y_index in range(X.shape[1]):\n",
    "            x_val = X[x_index, y_index]\n",
    "            y_val = Y[x_index, y_index]\n",
    "            res[-1].append(objective(np.array([[x_val, y_val]]).T))\n",
    "    res = np.array(res)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.contour(X, Y, res, 100)\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_contours(function_parabola)\n",
    "plt.scatter(np.array(var_history)[:,0], np.array(var_history)[:,1], s=10, c='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression problem (Prediction of a sinusoidal function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "x_train = torch.rand(100) * 20.0 - 10.0\n",
    "y_train = torch.sin(x_train) + torch.randn(x_train.shape) / 5\n",
    "x_train.unsqueeze_(1)\n",
    "y_train.unsqueeze_(1)\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'o')\n",
    "plt.title('noisy sin(x)')\n",
    "plt.xlabel('x_train')\n",
    "plt.ylabel('y_train');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset\n",
    "x_validation = torch.linspace(-10, 10, 100)\n",
    "y_validation = torch.sin(x_validation.data)\n",
    "x_validation.unsqueeze_(1)\n",
    "y_validation.unsqueeze_(1);\n",
    "plt.plot(x_validation.numpy(), y_validation.numpy(), 'o')\n",
    "plt.title('sin(x)')\n",
    "plt.xlabel('x_validation')\n",
    "plt.ylabel('y_validation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineNet(torch.nn.Module):\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(SineNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(1, n_hidden_neurons) # Fully connected layer\n",
    "        self.act1 = torch.nn.Sigmoid() # Sigmoidal activation function\n",
    "        self.fc2 = torch.nn.Linear(n_hidden_neurons, 1)\n",
    "\n",
    "    def forward(self, x): # Forward propagation\n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "sine_net = SineNet(50) # You can change number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, x, y):\n",
    "    y_pred = net.forward(x)\n",
    "\n",
    "    plt.plot(x.numpy(), y.numpy(), 'o', label='Groud truth')\n",
    "    plt.plot(x.numpy(), y_pred.data.numpy(), 'o', c='r', label='Prediction');\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$')\n",
    "\n",
    "predict(sine_net, x_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning algorithm (optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(sine_net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(pred, target): # loss function MSE (mean square error)\n",
    "    squares = (pred - target) ** 2\n",
    "    return squares.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_index in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = sine_net.forward(x_train)\n",
    "    loss_val = loss(y_pred, y_train)\n",
    "\n",
    "    loss_val.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "predict(sine_net, x_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The classification problem (Recognition of digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST('./', download=True, train=True)\n",
    "MNIST_test = torchvision.datasets.MNIST('./', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MNIST_train.train_data\n",
    "y_train = MNIST_train.train_labels\n",
    "X_test = MNIST_test.test_data\n",
    "y_test = MNIST_test.test_labels\n",
    "\n",
    "X_train = X_train.unsqueeze(1).float()\n",
    "X_test = X_test.unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0, 0])\n",
    "plt.show()\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        self.act1  = torch.nn.Tanh()\n",
    "        self.pool1 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "       \n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=6, out_channels=16, kernel_size=5, padding=0)\n",
    "        self.act2  = torch.nn.Tanh()\n",
    "        self.pool2 = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1   = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        self.act3  = torch.nn.Tanh()\n",
    "        \n",
    "        self.fc2   = torch.nn.Linear(120, 84)\n",
    "        self.act4  = torch.nn.Tanh()\n",
    "        \n",
    "        self.fc3   = torch.nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "lenet5 = LeNet5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lenet5 = lenet5.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning algorithm (optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(lenet5.parameters(), lr=1.0e-3)\n",
    "optimizer = torch.optim.Adam(lenet5.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "test_accuracy_history = []\n",
    "test_loss_history = []\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indexes = order[start_index:start_index+batch_size]\n",
    "        \n",
    "        X_batch = X_train[batch_indexes].to(device)\n",
    "        y_batch = y_train[batch_indexes].to(device)\n",
    "        \n",
    "        preds = lenet5.forward(X_batch) \n",
    "        \n",
    "        loss_value = loss(preds, y_batch)\n",
    "        loss_value.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    test_preds = lenet5.forward(X_test)\n",
    "    test_loss_history.append(loss(test_preds, y_test).data.cpu())\n",
    "    \n",
    "    accuracy = (test_preds.argmax(dim=1) == y_test).float().mean().data.cpu()\n",
    "    test_accuracy_history.append(accuracy)\n",
    "    \n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_loss_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_accuracy_history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
